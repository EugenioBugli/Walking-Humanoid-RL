{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    id='Humanoid-v4',\n",
    "    healthy_reward=5,                       # costant reward given after each timestep if the humanoid has an healthy posture\n",
    "    terminate_when_unhealthy=True,          # if the humanoid has not a healthy posture, hence is out of range, then terminate\n",
    "    healthy_z_range=(1.0, 2.0),             # z-coordinate of the torso the indicate if the humanoid has an healthy posture or not\n",
    "    exclude_current_positions_from_observation=False,\n",
    ")\n",
    "\n",
    "val_env = gym.make(\n",
    "    id='Humanoid-v4',\n",
    "    healthy_reward=5,                       # costant reward given after each timestep if the humanoid has an healthy posture\n",
    "    terminate_when_unhealthy=True,          # if the humanoid has not a healthy posture, hence is out of range, then terminate\n",
    "    healthy_z_range=(1.0, 2.0),              # z-coordinate of the torso the indicate if the humanoid has an healthy posture or not\n",
    "    render_mode='human',\n",
    "    exclude_current_positions_from_observation=False\n",
    ")\n",
    "\n",
    "# Get the state space and action space\n",
    "n_actions = env.action_space\n",
    "\n",
    "n_frames = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-0.4, 0.4, (17,), float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observation = val_env.step(val_env.action_space.sample())[0]\n",
    "\n",
    "reward = val_env.step(val_env.action_space.sample())[1]\n",
    "\n",
    "terminated = val_env.step(val_env.action_space.sample())[2] # bool\n",
    "\n",
    "truncated = val_env.step(val_env.action_space.sample())[3] # bool\n",
    "\n",
    "info = val_env.step(val_env.action_space.sample())[4] # dict\n",
    "\n",
    "dict_keys(['reward_linvel', 'reward_quadctrl', 'reward_alive', 'x_position', 'y_position', 'distance_from_origin', 'x_velocity', 'y_velocity', 'forward_reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.43694556e-03  8.83825264e-03  1.39218123e+00  9.99950099e-01\n",
      "  2.19622536e-03  2.09226175e-03  9.51830764e-03 -1.55894097e-02\n",
      "  6.04401659e-02  2.63836415e-02 -2.31511229e-02 -6.98137883e-02\n",
      " -6.29929493e-02 -1.44925785e-02  3.51736683e-02 -7.63490864e-03\n",
      " -9.45769460e-02 -1.09830712e-01 -2.02846543e-03 -1.93357797e-02\n",
      "  8.43695766e-04 -2.99385522e-03  9.32987267e-03  1.34712738e-02\n",
      "  2.39108645e-01 -1.88597709e-02 -2.22303731e-01 -3.93643096e-01\n",
      " -6.87697258e-01  1.26047870e+00 -1.36056845e+00  4.91477695e+00\n",
      "  2.78772731e+00 -2.20580589e+00 -5.73515752e+00 -6.49041267e+00\n",
      " -1.91604556e+00  2.93434793e+00 -7.36316774e-01 -1.03796191e+01\n",
      " -1.21773567e+01  1.76105268e-01 -2.28202195e+00  3.91633504e-01\n",
      " -2.06834691e-01 -1.68769288e-01  1.96021346e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  2.29983617e+00  2.28090642e+00  4.16339433e-02\n",
      "  2.05386194e-04  2.01910606e-02  1.58528983e-02 -4.96256076e-02\n",
      " -3.15781242e-02  4.35232559e+00  8.90746237e+00  9.50924244e-02\n",
      "  8.97217904e-02  1.06157092e-02 -7.85692722e-05  7.99279926e-03\n",
      "  1.03420089e-03 -4.11763999e-02 -5.46746055e-03  4.39064022e-01\n",
      "  2.26194671e+00  5.85140643e-02  4.58944751e-02  6.76504396e-02\n",
      "  3.22089093e-04  9.75185482e-03 -1.03027913e-03 -3.18726643e-01\n",
      "  5.55916359e-03  2.02396380e-01  6.61619413e+00  2.75415663e-01\n",
      "  2.38866800e-01  5.27226634e-02 -1.26881602e-02 -2.46605829e-02\n",
      " -7.82777901e-02 -1.37327271e-01 -4.38421032e-01 -8.71987869e-01\n",
      "  4.75175093e+00  9.37209908e-01  9.19166189e-01  2.57659740e-02\n",
      " -6.78010338e-03 -4.49891640e-02 -1.33887575e-01 -7.89896490e-02\n",
      " -2.36572285e-01 -1.56104038e+00  2.75569617e+00  1.05489620e+00\n",
      "  1.04375404e+00  1.83669370e-02 -4.55382191e-03 -4.10649029e-02\n",
      " -1.15124262e-01 -5.35767284e-02 -1.50200802e-01 -1.35446257e+00\n",
      "  1.76714587e+00  2.68375771e-01  2.26927810e-01  5.54215312e-02\n",
      "  1.11662788e-02 -1.78095666e-02  7.90816875e-02 -1.14845250e-01\n",
      "  4.58541111e-01 -8.42203038e-01  4.75175093e+00  9.17788823e-01\n",
      "  8.97839609e-01  2.78398620e-02  6.99217405e-03 -4.56680197e-02\n",
      "  1.38586494e-01 -7.78406047e-02  2.47889263e-01 -1.54216019e+00\n",
      "  2.75569617e+00  1.03628553e+00  1.02549287e+00  2.11839989e-02\n",
      "  6.70132671e-03 -5.71520918e-02  1.19401096e-01 -7.52884756e-02\n",
      "  1.57291295e-01 -1.34145474e+00  1.76714587e+00  4.26945063e-01\n",
      "  3.31010465e-01  1.27611904e-01  3.81024187e-02 -5.19481325e-02\n",
      "  1.76462470e-01  1.31718808e-01 -4.20258110e-01  7.16968779e-01\n",
      "  1.66108048e+00  3.17090317e-01  3.47539640e-01  1.84278470e-01\n",
      "  8.16818494e-02 -1.59828481e-01  1.26164022e-01  3.55189174e-01\n",
      " -2.98014771e-01  5.38260939e-01  1.22954019e+00  4.26648306e-01\n",
      "  3.31871649e-01  1.21805105e-01 -3.40734185e-02 -4.63617290e-02\n",
      " -1.74011078e-01  1.17770497e-01  4.12665067e-01  7.20759741e-01\n",
      "  1.66108048e+00  3.21943214e-01  3.45235163e-01  1.77385824e-01\n",
      " -7.88556502e-02 -1.55906661e-01 -1.27712362e-01  3.42718150e-01\n",
      "  2.98566684e-01  5.43533344e-01  1.22954019e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -3.75420750e-01 -7.04249587e-01  1.25942321e+00\n",
      "  5.54916346e-01 -1.85276580e-01 -2.21298022e-01 -3.92665845e-01\n",
      "  4.22680187e+00 -7.83296160e-02 -7.18571254e-01 -2.08828066e-01\n",
      " -2.91693818e-01  2.39243598e+00  4.23706043e+00 -2.36125956e-01\n",
      " -7.19558814e-01  1.47595869e-01 -2.85952614e-01 -5.67887070e-01\n",
      " -2.21340454e+00 -5.87451377e+00 -2.55321079e-01  1.69342303e-02\n",
      " -3.80211002e-01 -4.40498971e-01 -2.97234378e-01 -5.86740224e+00\n",
      "  5.03796059e-01 -3.33793981e-02 -4.21413924e-01 -4.40498971e-01\n",
      " -2.97234378e-01 -5.86740224e+00  5.03796059e-01 -3.33793981e-02\n",
      " -4.21413924e-01 -3.77272881e-01 -6.15994965e+00  7.06486382e-01\n",
      " -7.00090667e-01  1.96951183e-01  3.15640191e-01 -5.17919959e-01\n",
      "  6.02290789e+00  6.58800556e-01  4.04771037e+00  2.51047905e-01\n",
      "  1.32951105e-01 -5.17919959e-01  6.02290789e+00  6.58800556e-01\n",
      "  4.04771037e+00  2.51047905e-01  1.32951105e-01 -2.65544444e-01\n",
      "  9.91460109e-01 -2.79698993e-01 -4.81480900e-02 -1.28414674e-01\n",
      " -2.01703221e-01 -2.59553732e-01  7.13076700e-01 -2.78935028e-03\n",
      " -5.39230324e-02 -1.75738674e-01 -2.49154152e-01 -5.46727795e-01\n",
      " -7.39155037e-01  1.05721862e+00  5.39243222e-01 -2.74692821e-01\n",
      " -1.92584378e-01 -5.29544879e-01 -2.12260543e+00 -3.31849164e-01\n",
      "  5.12239990e-01 -3.66894509e-02 -4.29959297e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -3.07341605e+01 -7.10550696e+00  9.93423983e+00\n",
      " -3.86688739e+01 -3.23428631e+01 -5.80505624e+01  1.53111562e+01\n",
      "  3.12685221e+01 -4.69797738e+00 -8.33271861e+01 -3.42796475e+01\n",
      "  3.37588787e+00 -3.49459834e+00 -5.41304015e+00  2.48036571e+00\n",
      "  2.26970725e+00  7.68917426e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n",
      "----\n",
      "[-0.07105507 -0.3073416   0.0993424  -0.38668874 -0.32342863 -0.19350187\n",
      "  0.07655578  0.31268522 -0.04697977 -0.2777573  -0.17139824  0.13503551\n",
      " -0.13978393 -0.2165216   0.09921463  0.09078829  0.30756697]\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "reward = []\n",
    "for _ in range(10000):\n",
    "    action = env.action_space.sample()\n",
    "    obs, rew, _, _, info= env.step(action)\n",
    "    print(obs)\n",
    "    print('----')\n",
    "    print(action)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1687692882896362\n",
      "(17,)\n"
     ]
    }
   ],
   "source": [
    "print(obs[45])\n",
    "print(action.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module) :\n",
    "    def __init__(self, input_size, hidden_size, n_actions, init_weight, min_act_value, lr, device=torch.device('cpu')):\n",
    "        super(Actor, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_actions = n_actions\n",
    "        self.init_weight = init_weight\n",
    "        self.min_act_value = min_act_value\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=self.input_size,\n",
    "            out_features=self.hidden_size\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=self.hidden_size,\n",
    "            out_features=self.hidden_size\n",
    "        )\n",
    "\n",
    "        self.mean_fc3 = nn.Linear(\n",
    "            in_features= self.hidden_size,\n",
    "            out_features=self.n_actions\n",
    "        )\n",
    "\n",
    "        self.mean_fc3.weight.data.uniform_(-self.init_weight, self.init_weight)\n",
    "        self.mean_fc3.bias.data.uniform_(-self.init_weight, self.init_weight)\n",
    "\n",
    "        self.log_std_fc3 = nn.Linear(\n",
    "            in_features= self.hidden_size,\n",
    "            out_features=self.n_actions\n",
    "        )\n",
    "\n",
    "        self.log_std_fc3.weight.data.uniform_(-self.init_weight, self.init_weight)\n",
    "        self.log_std_fc3.bias.data.uniform_(-self.init_weight, self.init_weight)\n",
    "\n",
    "        self.optimizer = optim.Adam(params=self.parameters(), lr=self.lr)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "\n",
    "        x = self.relu(self.fc2(x))\n",
    "\n",
    "        return self.mean_fc3(x), self.log_std_fc3(x)   # mean, log_std\n",
    "    \n",
    "    def act(self, state, greedy=False):\n",
    "\n",
    "        mean, log_std = self.forward(state)\n",
    "\n",
    "        action = self.tanh(mean)\n",
    "\n",
    "        if not greedy: # explore\n",
    "\n",
    "            gaussian = Normal(0, 1)\n",
    "            z = gaussian.sample()\n",
    "            action = self.tanh(mean + log_std.exp()*z)\n",
    "\n",
    "        # clamp obtained values to [-0.4, 0.4]\n",
    "\n",
    "        action_clamped = torch.clamp(action, \n",
    "                                     min=-self.min_act_value,\n",
    "                                     max=self.min_act_value)\n",
    "        \n",
    "        return action_clamped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, init_weight, lr, device=torch.device('cpu')):\n",
    "        super(Critic, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.init_weight = init_weight\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=self.input_size,\n",
    "            out_features=self.hidden_size\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=self.hidden_size,\n",
    "            out_features=self.hidden_size\n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Linear(\n",
    "            in_features= self.hidden_size,\n",
    "            out_features= 1\n",
    "        )\n",
    "\n",
    "        self.fc3.weight.data.uniform_(-self.init_weight, self.init_weight)\n",
    "        self.fc3.bias.data.uniform_(-self.init_weight, self.init_weight)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "\n",
    "        x = self.relu(self.fc2(x))\n",
    "\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action_Critic():\n",
    "    def __init__(self, input_size, hidden_size, n_actions, init_weight, min_act_value, act_lr, crt_lr, num_episodes, device=torch.device('cpu')):\n",
    "        self.device = device\n",
    "\n",
    "        self.num_episodes = num_episodes\n",
    "\n",
    "        self.Actor = Actor(\n",
    "            input_size= input_size,\n",
    "            hidden_size= hidden_size,\n",
    "            n_actions= n_actions,\n",
    "            init_weight= init_weight,\n",
    "            min_act_value= min_act_value,\n",
    "            lr= act_lr,\n",
    "            device= self.device\n",
    "        )\n",
    "\n",
    "        self.Critic = Critic(\n",
    "            input_size= input_size,\n",
    "            hidden_size= hidden_size,\n",
    "            init_weight= init_weight,\n",
    "            lr= crt_lr,\n",
    "            device= self.device\n",
    "        )\n",
    "    def save(self):\n",
    "        torch.save(self.state_dict(), 'model.pt')\n",
    "\n",
    "    def load(self):\n",
    "        self.load_state_dict(torch.load('model.pt', map_location=self.device))\n",
    "\n",
    "    def to(self, device):\n",
    "        ret = super().to(device)\n",
    "        ret.device = device\n",
    "        return ret\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        E = gym.make(\n",
    "            id='Humanoid-v4',\n",
    "            healthy_reward=5,                       \n",
    "            terminate_when_unhealthy=True,          \n",
    "            healthy_z_range=(1.0, 2.0),             \n",
    "            exclude_current_positions_from_observation=False,\n",
    "        )\n",
    "\n",
    "        scores = deque(maxlen=100)\n",
    "        act_losses = deque(maxlen=10)\n",
    "        crt_losses = deque(maxlen=10)\n",
    "\n",
    "        for iter in range(self.num_episodes):\n",
    "\n",
    "        # CONTAINERS\n",
    "\n",
    "            Rewards = []\n",
    "            Log_prob = []\n",
    "            Values = []\n",
    "            obs_next = E.reset()\n",
    "            done_next = False\n",
    "\n",
    "        # ROLLOUT\n",
    "            t = 0\n",
    "\n",
    "            while not done_next:\n",
    "\n",
    "                obs = obs_next\n",
    "                done = done_next\n",
    "\n",
    "                action = self.Actor.act(obs)\n",
    "\n",
    "                obs_next, reward, done, truncated, info = E.step(action)\n",
    "\n",
    "                value = self.Critic.forward(obs_next)\n",
    "\n",
    "                Values.append(value)\n",
    "                Rewards.append(reward)\n",
    "\n",
    "                done_next = done | truncated\n",
    "\n",
    "                # check if z-coordinate of torso is inside the healthy_range\n",
    "\n",
    "\n",
    "\n",
    "                t+=1 # update counter\n",
    "\n",
    "            scores.append(sum(Rewards))\n",
    "\n",
    "        # LEARNING\n",
    "\n",
    "            # compute Advantage\n",
    "\n",
    "            # compute Log_Prob\n",
    "\n",
    "            actor_loss = 0\n",
    "            critic_loss = 0\n",
    "\n",
    "            act_losses.append(actor_loss)\n",
    "            crt_losses.append(critic_loss)\n",
    "\n",
    "        # UPDATES\n",
    "\n",
    "            # Actor\n",
    "            self.Actor.optimizer.no_grad()\n",
    "            actor_loss.backward()\n",
    "            self.Actor.optimizer.step()\n",
    "\n",
    "            # Critic\n",
    "            self.Critic.optimizer.no_grad()\n",
    "            critic_loss.backward()\n",
    "            self.Critic.optimizer.step()\n",
    "\n",
    "        # SAVE\n",
    "\n",
    "\n",
    "            if iter % 10:\n",
    "\n",
    "                print(f'''Episode {iter}\n",
    "                    \\tAverage Score: {np.mean(scores)}\n",
    "                    \\ttAverage Critic Loss: {np.mean(act_losses)}\n",
    "                    \\tAverage Actor Loss: {np.mean(crt_losses)}\n",
    "                    \\tLast Score: {sum(Rewards)}\\n''')\n",
    "                \n",
    "                self.save()\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(Agent_AC):\n",
    "    return 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
